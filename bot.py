import logging
import os
import asyncio
from telegram import Update, KeyboardButton, ReplyKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    ContextTypes, filters, Defaults
)
import openai
import aiohttp
import subprocess

# === –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_BOT_TOKEN or not OPENAI_API_KEY:
    raise EnvironmentError("–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã TELEGRAM_BOT_TOKEN –∏–ª–∏ OPENAI_API_KEY")

openai.api_key = OPENAI_API_KEY

# === URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –±–∏–Ω–∞—Ä–Ω–∏–∫–æ–≤ ===
FFMPEG_URL = "https://github.com/SashaVeo/TG_bot/releases/download/v1.0/ffmpeg"
FFPROBE_URL = "https://github.com/SashaVeo/TG_bot/releases/download/v1.0/ffprobe"

# === –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# === –ò—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–æ–≤ ===
chat_histories = {
    "default": {},
    "psychologist": {},
    "astrologer": {}
}
MAX_HISTORY_PAIRS = 10

def get_chat_history(chat_id, mode):
    history_store = chat_histories.get(mode, {})
    return history_store.setdefault(chat_id, [])

def trim_chat_history(history):
    return history[-(MAX_HISTORY_PAIRS * 2):] if len(history) > MAX_HISTORY_PAIRS * 2 else history

def build_keyboard():
    keyboard = [
        [KeyboardButton("üåç –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")],
        [KeyboardButton("üí¨ –ü—Å–∏—Ö–æ–ª–æ–≥")],
        [KeyboardButton("üîÆ –ê—Å—Ç—Ä–æ–ª–æ–≥")],
        [KeyboardButton("üîô –ù–∞–∑–∞–¥")]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

# === –ö–æ–º–∞–Ω–¥—ã ===
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üòä –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç —Å GPT-4o. –í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=build_keyboard()
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ –∏–∑ –º–µ–Ω—é.", reply_markup=build_keyboard())

# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ ===
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    file = await update.message.voice.get_file()
    ogg_path = f"voice_{update.message.message_id}.ogg"
    mp3_path = f"voice_{update.message.message_id}.mp3"

    await file.download_to_drive(ogg_path)
    try:
        subprocess.run(["./bin/ffmpeg", "-i", ogg_path, mp3_path], check=True)
        with open(mp3_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe("whisper-1", audio_file)
            update.message.text = transcript["text"]
            await handle_message(update, context)
    except Exception as e:
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ")
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
    finally:
        if os.path.exists(ogg_path):
            os.remove(ogg_path)
        if os.path.exists(mp3_path):
            os.remove(mp3_path)

# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π ===
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    user_id = update.effective_user.id
    text = update.message.text.strip()

    mode = context.user_data.get("mode", "default")

    if text == "üîô –ù–∞–∑–∞–¥":
        context.user_data["mode"] = "default"
        await update.message.reply_text("–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:", reply_markup=build_keyboard())
        return

    if text == "üåç –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ":
        context.user_data["mode"] = "image"
        await update.message.reply_text("üñã –ù–∞–ø–∏—à–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—á–µ—à—å —Å–æ–∑–¥–∞—Ç—å:")
        return

    if text == "üí¨ –ü—Å–∏—Ö–æ–ª–æ–≥":
        context.user_data["mode"] = "psychologist"
        await update.message.reply_text("üß† –ü—Å–∏—Ö–æ–ª–æ–≥ —Å–ª—É—à–∞–µ—Ç —Ç–µ–±—è. –†–∞—Å—Å–∫–∞–∂–∏, —á—Ç–æ —Ç—Ä–µ–≤–æ–∂–∏—Ç.")
        return

    if text == "üîÆ –ê—Å—Ç—Ä–æ–ª–æ–≥":
        context.user_data["mode"] = "astrologer"
        await update.message.reply_text("üîÆ –Ø –∞—Å—Ç—Ä–æ–ª–æ–≥. –í–≤–µ–¥–∏ –¥–∞—Ç—É —Ä–æ–∂–¥–µ–Ω–∏—è, –≤—Ä–µ–º—è –∏ –≥–æ—Ä–æ–¥.")
        return

    if mode == "image":
        context.user_data["mode"] = "default"
        await update.message.reply_text("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
        try:
            response = openai.images.generate(
                prompt=text,
                model="dall-e-3",
                n=1,
                size="1024x1024"
            )
            image_url = response.data[0].url
            await update.message.reply_photo(photo=image_url)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return

    history = get_chat_history(chat_id, mode)
    history.append({"role": "user", "content": text})
    history = trim_chat_history(history)

    system_prompt = {
        "default": "–¢—ã —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –ø–æ–¥—Ä–æ–±–Ω–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ.",
        "psychologist": "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥. –ì–æ–≤–æ—Ä–∏ –º—è–≥–∫–æ, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ.",
        "astrologer": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –∞—Å—Ç—Ä–æ–ª–æ–≥. –ò—Å–ø–æ–ª—å–∑—É–π –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è, —Å–æ–≤–µ—Ç—ã –∏ —Ç–µ—Ä–º–∏–Ω—ã."
    }.get(mode, "–¢—ã —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫.")

    messages = [{"role": "system", "content": system_prompt}] + history

    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.8,
            max_tokens=1000
        )
        bot_reply = response.choices[0].message.content
        history.append({"role": "assistant", "content": bot_reply})
        chat_histories[mode][chat_id] = trim_chat_history(history)

        await update.message.reply_text(bot_reply, reply_markup=build_keyboard())
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ OpenAI: {e}")
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –ø–æ–∑–∂–µ.")

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ===
async def ensure_ffmpeg():
    os.makedirs("./bin", exist_ok=True)
    for name, url in {"ffmpeg": FFMPEG_URL, "ffprobe": FFPROBE_URL}.items():
        path = f"./bin/{name}"
        if not os.path.isfile(path):
            print(f"‚¨áÔ∏è  –°–∫–∞—á–∏–≤–∞–µ–º {path}...")
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as resp:
                    with open(path, "wb") as f:
                        f.write(await resp.read())
        os.chmod(path, 0o755)
        print(f"‚úÖ {path} –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")

if __name__ == "__main__":
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    asyncio.run(ensure_ffmpeg())

    defaults = Defaults(parse_mode=None)
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).defaults(defaults).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logging.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ —Å–ª—É—à–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è.")
    app.run_polling()
