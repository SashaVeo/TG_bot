import logging
import openai
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (ApplicationBuilder, CommandHandler,
                          ContextTypes, MessageHandler,
                          CallbackQueryHandler, filters)

# === –ö–õ–Æ–ß–ò ===
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
openai.api_key = os.getenv("OPENAI_API_KEY")

# –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–æ–≤
chat_histories = {}

# –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)

def get_chat_history(chat_id):
    return chat_histories.setdefault(chat_id, [])

def handle_response(chat_id, text):
    chat_history = get_chat_history(chat_id)
    user_message = {"role": "user", "content": text}
    chat_history.append(user_message)

    messages = [
        {
            "role": "system",
            "content": "–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ—Ç–≤–µ—á–∞—é—â–∏–π –ø–æ–¥—Ä–æ–±–Ω–æ, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ. –ù–µ —Å–æ–∫—Ä–∞—â–∞–π –æ—Ç–≤–µ—Ç—ã."
        }
    ] + chat_history

    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.7,
        max_tokens=1000
    )

    bot_reply = response["choices"][0]["message"]["content"]
    chat_history.append({"role": "assistant", "content": bot_reply})
    return bot_reply

# –°—Ç–∞—Ä—Ç–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞ —Å –∫–Ω–æ–ø–∫–æ–π
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [[InlineKeyboardButton("üñº –°–¥–µ–ª–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", callback_data="generate_image")]]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –Ω–∞ GPT-4o. –ù–∞–ø–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –≤—ã–±–µ—Ä–∏ –æ–ø—Ü–∏—é üëá",
        reply_markup=reply_markup
    )

# –ö–æ–º–∞–Ω–¥–∞ –ø–æ–º–æ—â–∏
async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ù–∞–ø–∏—à–∏ –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ ‚Äî —è –ø–æ–º–æ–≥—É! –ß—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –Ω–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É.")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏—è –Ω–∞ –∫–Ω–æ–ø–∫—É
async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    if query.data == "generate_image":
        await query.message.reply_text("–û–ø–∏—à–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å —É–≤–∏–¥–µ—Ç—å. –Ø —Å–æ–∑–¥–∞–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ —Ç–≤–æ–µ–º—É –æ–ø–∏—Å–∞–Ω–∏—é ‚ú®")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    user_input = update.message.text

    if any(word in user_input.lower() for word in ["–Ω–∞—Ä–∏—Å—É–π", "—Å–¥–µ–ª–∞–π", "—Å–æ–∑–¥–∞–π", "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"]):
        try:
            response = openai.Image.create(
                prompt=user_input,
                n=1,
                size="512x512"
            )
            image_url = response["data"][0]["url"]
            await update.message.reply_photo(photo=image_url)
        except Exception as e:
            await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: " + str(e))
    else:
        reply = handle_response(chat_id, user_input)
        await update.message.reply_text(reply)

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == "__main__":
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CallbackQueryHandler(button_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    app.run_polling()
